# üéôÔ∏è Lokal R√∂ststyrd AI-Assistent f√∂r Raspberry Pi 5

En helt lokal, r√∂ststyrd AI-assistent som k√∂rs p√• Raspberry Pi 5. Systemet kan lyssna, tolka och svara med tal, samt integrera med automatiseringsfl√∂den i n8n via MQTT (HiveMQ Cloud).

## ‚ú® Funktioner

- **Lokal bearbetning**: All r√∂stbearbetning sker lokalt p√• Pi:n
- **Wake Word Detection**: Aktiveras med "Hey Genio" (eller anpassat ord)
- **Voice Activity Detection (VAD)**: Intelligent detektering av tal
- **Speech-to-Text (STT)**: Lokal transkribering med Vosk
- **MQTT Integration**: Kommunicerar med n8n via HiveMQ Cloud
- **Text-to-Speech (TTS)**: Lokal talsyntes med Piper
- **Privacy-first**: Ingen r√∂stdata skickas till molnet

## üß© Arkitektur

Systemet best√•r av fem huvudmoduler:

| Modul | Funktion | Teknologi |
|-------|----------|-----------|
| **Wake Word** | Detekterar aktiveringsord | Porcupine |
| **VAD** | Avg√∂r n√§r anv√§ndaren talar | WebRTC VAD / Silero VAD |
| **STT** | Transkriberar tal till text | Vosk |
| **Dialog/MQTT** | Kommunicerar med n8n | Paho MQTT |
| **TTS** | Syntetiserar svar till tal | Piper |

## üìã F√∂ruts√§ttningar

### H√•rdvara
- Raspberry Pi 5 (rekommenderat 4GB+ RAM)
- USB-mikrofon eller HAT med mikrofon
- H√∂gtalare (USB, 3.5mm eller HDMI-ljud)
- MicroSD-kort (32GB+ rekommenderat)

### Mjukvara
- Raspberry Pi OS (64-bit rekommenderat)
- Python 3.9 eller senare
- Internetuppkoppling f√∂r MQTT

## üöÄ Installation

### 1. Klona repositoryt
```bash
git clone https://github.com/fredrik-svg/ai.git
cd ai
```

### 2. Installera systemberoenden
```bash
sudo apt-get update
sudo apt-get install -y python3-pip python3-venv portaudio19-dev libopenblas-dev
```

### 3. Skapa virtuell milj√∂
```bash
python3 -m venv venv
source venv/bin/activate
```

### 4. Installera Python-paket
```bash
pip install -r requirements.txt
```

### 5. Ladda ner modeller

#### Porcupine Wake Word (kr√§ver Access Key)
Registrera dig p√• [Picovoice Console](https://console.picovoice.ai/) f√∂r att f√• en gratis Access Key.

**F√∂r anpassade wake words:**
1. G√• till Picovoice Console och skapa ett anpassat wake word
2. Ladda ner `.ppn`-filen
3. Placera den i projektets katalog (t.ex. `models/wake_words/`)
4. Uppdatera `keyword_path` i `config.yaml` med s√∂kv√§gen till din `.ppn`-fil

#### Vosk STT modell (Svenska)
```bash
mkdir -p models/vosk
cd models/vosk

# Ladda ner svensk Vosk-modell (liten, snabb, ca 40MB)
wget https://alphacephei.com/vosk/models/vosk-model-small-sv-rhasspy-0.15.zip
unzip vosk-model-small-sv-rhasspy-0.15.zip
rm vosk-model-small-sv-rhasspy-0.15.zip

# Alternativ: St√∂rre modell f√∂r b√§ttre noggrannhet (ca 1.5GB)
# wget https://alphacephei.com/vosk/models/vosk-model-sv-se-0.22.zip
# unzip vosk-model-sv-se-0.22.zip
# rm vosk-model-sv-se-0.22.zip

cd ../..
```

#### Piper TTS modell
```bash
mkdir -p models/piper
cd models/piper
wget https://huggingface.co/rhasspy/piper-voices/resolve/main/sv/sv_SE/lisa/medium/sv_SE-lisa-medium.onnx
wget https://huggingface.co/rhasspy/piper-voices/resolve/main/sv/sv_SE/lisa/medium/sv_SE-lisa-medium.onnx.json
cd ../..
```

### 6. Konfigurera
Kopiera exempel-konfigurationen och anpassa den:
```bash
cp config.example.yaml config.yaml
nano config.yaml
```

Redigera `config.yaml` och fyll i:
- Picovoice Access Key
- HiveMQ Cloud MQTT-inst√§llningar (URL, port, anv√§ndarnamn, l√∂senord)
- MQTT-topics f√∂r n8n-integration

## ‚öôÔ∏è Konfiguration

Redigera `config.yaml`:

```yaml
# Wake Word Detection
wake_word:
  access_key: "DIN_PICOVOICE_ACCESS_KEY"
  keyword: "hey-genio"  # Built-in keyword (anv√§nds bara om keyword_path inte √§r satt)
  keyword_path: null  # S√∂kv√§g till anpassad .ppn-fil (t.ex., "models/wake_words/genio.ppn")
  sensitivity: 0.5

# Voice Activity Detection
vad:
  sample_rate: 16000
  frame_duration: 30  # ms
  
# Speech to Text (Vosk)
stt:
  model_path: "models/vosk/vosk-model-small-sv-rhasspy-0.15"  # S√∂kv√§g till Vosk-modell
  language: "sv"  # svenska
  sample_rate: 16000  # Samplingsfrekvens i Hz

# MQTT / n8n Integration
mqtt:
  broker: "YOUR_HIVEMQ_CLUSTER.hivemq.cloud"
  port: 8883
  username: "your_username"
  password: "your_password"
  topic_send: "assistant/input"
  topic_receive: "assistant/output"
  use_tls: true

# Text to Speech
tts:
  model_path: "models/piper/sv_SE-lisa-medium.onnx"
  config_path: "models/piper/sv_SE-lisa-medium.onnx.json"

# Audio Settings
audio:
  input_device: null  # null = default device
  output_device: null  # null = default device
  sample_rate: 16000
  channels: 1
```

## üéØ Anv√§ndning

### Starta assistenten
```bash
python main.py
```

### Interagera
1. S√§g wake word: "Hey Genio"
2. V√§nta p√• bekr√§ftelseljud
3. S√§g din fr√•ga eller kommando
4. Assistenten svarar via h√∂gtalarna

### Exempel p√• interaktion
```
Anv√§ndare: "Hey Genio"
System: *pling*
Anv√§ndare: "Vad √§r klockan?"
Assistent: "Klockan √§r 14:30"
```

## üîß n8n Integration

### Setup i n8n
1. Skapa ett nytt workflow i n8n
2. L√§gg till en **MQTT Trigger** node
   - Anslut till din HiveMQ Cloud broker
   - Lyssna p√• topic: `assistant/input`
3. Bearbeta inkommande text (t.ex. med AI, API-anrop, etc.)
4. Skicka svar via **MQTT** node
   - Skicka till topic: `assistant/output`

### Exempel n8n Workflow
```
MQTT Trigger (assistant/input)
  ‚Üì
Function Node (bearbeta text)
  ‚Üì
OpenAI/LLM Node (generera svar)
  ‚Üì
MQTT Send (assistant/output)
```

## üìÅ Projektstruktur

```
ai/
‚îú‚îÄ‚îÄ main.py                 # Huvudapplikation
‚îú‚îÄ‚îÄ config.yaml             # Konfiguration
‚îú‚îÄ‚îÄ config.example.yaml     # Exempel-konfiguration
‚îú‚îÄ‚îÄ requirements.txt        # Python-beroenden
‚îú‚îÄ‚îÄ README.md              # Denna fil
‚îú‚îÄ‚îÄ modules/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ wake_word.py       # Porcupine wake word detection
‚îÇ   ‚îú‚îÄ‚îÄ vad.py             # Voice Activity Detection
‚îÇ   ‚îú‚îÄ‚îÄ stt.py             # Speech-to-Text (Faster-Whisper)
‚îÇ   ‚îú‚îÄ‚îÄ mqtt_handler.py    # MQTT kommunikation
‚îÇ   ‚îî‚îÄ‚îÄ tts.py             # Text-to-Speech (Piper)
‚îî‚îÄ‚îÄ models/
    ‚îî‚îÄ‚îÄ piper/             # TTS-modeller
```

## üêõ Fels√∂kning

### Mikrofonproblem
```bash
# Lista tillg√§ngliga ljudenheter
python -c "import sounddevice as sd; print(sd.query_devices())"

# Testa mikrofon
arecord -l
arecord -d 5 test.wav
aplay test.wav
```

### Wake Word detektion √§r l√•ngsam eller missar aktivering
Om du har sv√•rt att f√• respons p√• wake word:

1. **Justera k√§nslighet**: √ñka `sensitivity` v√§rdet i `config.yaml` fr√•n 0.5 till 0.6-0.7
   ```yaml
   wake_word:
     sensitivity: 0.7  # H√∂gre v√§rde = mer responsiv
   ```

2. **Kontrollera mikrofonplacering**: Se till att mikrofonen √§r tillr√§ckligt n√§ra och inte blockerad

3. **Testa olika wake words**: Prova olika inbyggda wake words eller skapa ett anpassat

4. **Kontrollera systembelastning**: K√∂r `top` f√∂r att se om CPU √§r √∂verbelastad

### STT (Speech-to-Text) kvalitetsproblem
Om r√∂sttranskriptionen √§r d√•lig eller missar ord:

1. **Anv√§nd st√∂rre Vosk-modell**: Byt fr√•n small till den st√∂rre svenska modellen
   ```yaml
   stt:
     model_path: "models/vosk/vosk-model-sv-se-0.22"  # St√∂rre modell (~1.5GB)
   ```
   Ladda ner den st√∂rre modellen:
   ```bash
   cd models/vosk
   wget https://alphacephei.com/vosk/models/vosk-model-sv-se-0.22.zip
   unzip vosk-model-sv-se-0.22.zip
   rm vosk-model-sv-se-0.22.zip
   cd ../..
   ```

2. **Kontrollera mikrofonkvalitet**: Testa med `arecord` och lyssna p√• inspelningen
   ```bash
   arecord -d 5 -f cd test.wav && aplay test.wav
   ```

3. **Justera mikrofonens volym**: √ñka mikrofonniv√•n med alsamixer
   ```bash
   alsamixer
   # Tryck F4 f√∂r capture och justera niv√•n
   ```

**Tips f√∂r b√§sta svenska igenk√§nning med Vosk**:
- Tala tydligt och i normal hastighet
- Vosk fungerar b√§st med ren, tydlig ljudinspelning
- Undvik bakgrundsljud och eko om m√∂jligt
- Den mindre modellen (small) √§r snabbare men mindre noggrann
- Den st√∂rre modellen (0.22) ger b√§ttre resultat f√∂r komplexa meningar

### ONNX Runtime GPU-varningar
Om du ser varningar om GPU-enheter som inte hittas (t.ex. "GPU device discovery failed"):
```
[W:onnxruntime:Default, device_discovery.cc:164 DiscoverDevicesForPlatform] 
GPU device discovery failed: device_discovery.cc:89 ReadFileContents 
Failed to open file: "/sys/class/drm/card1/device/vendor"
```

**OBS:** Med Vosk-implementationen b√∂r dessa varningar inte visas l√§ngre, 
eftersom Vosk inte anv√§nder ONNX Runtime. Detta var ett problem med Faster-Whisper.

### MQTT-anslutningsproblem
- Kontrollera att HiveMQ Cloud-credentials √§r korrekta
- Verifiera att port 8883 √§r √∂ppen i din firewall
- Testa anslutning med MQTT Explorer eller mosquitto_pub/sub

### Prestandaproblem
- Anv√§nd den mindre Vosk-modellen (vosk-model-small-sv-rhasspy-0.15)
- Vosk √§r optimerad f√∂r Raspberry Pi och anv√§nder mindre resurser √§n Whisper
- S√§kerst√§ll tillr√§cklig kylning
- Om Pi:n √§r √∂verbelastad, st√§ng av on√∂diga processer

## üìù Licens

MIT License - se LICENSE-filen f√∂r detaljer.

## ü§ù Bidrag

Pull requests √§r v√§lkomna! F√∂r st√∂rre √§ndringar, √∂ppna g√§rna en issue f√∂rst.

## üìß Kontakt

F√∂r fr√•gor eller support, skapa en issue i detta repository.

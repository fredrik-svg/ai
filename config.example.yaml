# Wake Word Detection
wake_word:
  access_key: "YOUR_PICOVOICE_ACCESS_KEY_HERE"
  keyword: "hey-genio"  # Built-in keyword name (ignored if keyword_path is set)
  keyword_path: null  # Path to custom .ppn file (e.g., "models/wake_words/my_custom_word.ppn")
  sensitivity: 0.5  # Range: 0.0-1.0. Lower = fewer false positives but may miss wake word. Higher = more responsive but more false positives. Try 0.6-0.7 if experiencing responsiveness issues.

# Voice Activity Detection
vad:
  sample_rate: 16000
  frame_duration: 30  # milliseconds
  mode: 3  # 0=Quality, 1=Low Bitrate, 2=Aggressive, 3=Very Aggressive
  
# Speech to Text
stt:
  model: "base"  # Options: tiny, base, small, medium, large-v2, large-v3
  language: "sv"  # Swedish
  device: "cpu"  # cpu or cuda
  compute_type: "int8"  # int8, int8_float16, float16, float32
  
  # Transcription quality parameters
  beam_size: 8  # Beam size for decoding (5-10 recommended, higher = better quality but slower)
  temperature: 0.0  # Temperature for sampling (0.0 = deterministic, more consistent results)
  
  # Initial prompt to guide the model for better Swedish recognition
  # This helps the model understand context and improves accuracy for Swedish
  # Include common Swedish words and sentence structures to prime the model
  initial_prompt: "Detta är en konversation på svenska med vardagliga fraser och meningar."  # "This is a conversation in Swedish with everyday phrases and sentences."
  
  # Conditioning on previous text improves continuity and accuracy for longer sentences
  condition_on_previous_text: true  # Use previous segments as context for better sentence flow
  
  # Voice Activity Detection (VAD) filtering
  vad_filter: true  # Enable VAD to filter out silence
  vad_min_silence_duration: 700  # Minimum silence duration in ms (increased from 500ms to avoid cutting off speech)

# MQTT / n8n Integration
mqtt:
  broker: "your-cluster.hivemq.cloud"
  port: 8883
  username: "your_mqtt_username"
  password: "your_mqtt_password"
  topic_send: "assistant/input"
  topic_receive: "assistant/output"
  use_tls: true
  keepalive: 60
  qos: 1

# Text to Speech
tts:
  model_path: "models/piper/sv_SE-lisa-medium.onnx"
  config_path: "models/piper/sv_SE-lisa-medium.onnx.json"
  speaker: 0

# Audio Settings
audio:
  input_device: null  # null = default device, or device index number
  output_device: null  # null = default device, or device index number
  sample_rate: 16000
  channels: 1
  chunk_size: 1024

# Logging
logging:
  level: "INFO"  # DEBUG, INFO, WARNING, ERROR, CRITICAL
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
